{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEEPSEEK_API_KEY found\n",
      "OPENAI_API_KEY found\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from paperqa.agents.main import agent_query\n",
    "from paperqa.settings import Settings, AgentSettings, IndexSettings, AnswerSettings, ParsingSettings, PromptSettings\n",
    "\n",
    "from src.build_search_index import build_search_index, process_bibtex_and_pdfs, create_manifest_file\n",
    "from src.query_answer_index import query_answer_index\n",
    "from src.utils import pretty_print_text\n",
    "\n",
    "# Boolean variable to determine if logs should also be printed to the console\n",
    "print_logging = False\n",
    "\n",
    "# Generate a timestamp for the log file name\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "logging_dir = Path(\".\") / \"logs\"\n",
    "logging_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Log file path\n",
    "log_file_path = logging_dir / f\"log_{timestamp}.log\"\n",
    "\n",
    "# Configure global logging\n",
    "handlers = []\n",
    "\n",
    "# Add file handler\n",
    "file_handler = logging.FileHandler(log_file_path)\n",
    "file_handler.setLevel(logging.INFO)  # Set desired file log level\n",
    "file_formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "file_handler.setFormatter(file_formatter)\n",
    "handlers.append(file_handler)\n",
    "\n",
    "# Optionally add console handler\n",
    "if print_logging:\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.INFO)  # Set desired console log level\n",
    "    console_formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "    console_handler.setFormatter(console_formatter)\n",
    "    handlers.append(console_handler)\n",
    "\n",
    "# Set up the root logger\n",
    "logging.basicConfig(level=logging.INFO, handlers=handlers)\n",
    "\n",
    "# NOTE: these are the paths that should be configured\n",
    "export_directory_name = \"MS_EXPORT\"\n",
    "project_dir = Path(\".\")\n",
    "#project_dir = Path(\"/\") / \"Users\" / \"pschafer\" / \"Projects\" / \"MS_expert\"\n",
    "\n",
    "# default paths\n",
    "data_dir = project_dir / \"data\"\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "paper_directory = data_dir / export_directory_name\n",
    "index_directory = data_dir / f\"{export_directory_name}_index\"\n",
    "bibtex_file = paper_directory / f\"{export_directory_name}.bib\"\n",
    "manifest_file = data_dir / f\"{export_directory_name}_manifest.csv\"\n",
    "index_name = f\"pqa_index_{export_directory_name}\"\n",
    "\n",
    "# create manifest file from bibtex\n",
    "processed_df = process_bibtex_and_pdfs(bibtex_file=bibtex_file, paper_directory=paper_directory)\n",
    "create_manifest_file(manifest_df=processed_df, manifest_file=manifest_file)\n",
    "\n",
    "#manifest_from_bibtex(bibtex_file=bibtex_file, \n",
    "#                     paper_directory=paper_directory, \n",
    "#                     manifest_file=manifest_file)\n",
    "\n",
    "# set paperQA settings\n",
    "#default_lmm = \"gpt-4o-mini\" # smaller than default which is gpt-4o (bc cheaper)\n",
    "default_lmm = \"deepseek/deepseek-chat\" # see https://docs.litellm.ai/docs/providers/deepseek\n",
    "\n",
    "index_settings = IndexSettings(\n",
    "    name = index_name,\n",
    "    paper_directory = paper_directory,\n",
    "    manifest_file = manifest_file,\n",
    "    index_directory = index_directory,\n",
    "    use_absolute_paper_directory = False,\n",
    "    recurse_subdirectories = True,\n",
    "    concurrency = 1, # \"number of concurrent filesystem reads for indexing (probably not important anymore since I avoid calling S2)\"\n",
    ")\n",
    "\n",
    "agent_settings = AgentSettings(\n",
    "    agent_llm = default_lmm,\n",
    "    index = index_settings,\n",
    "    index_concurrency = index_settings.concurrency\n",
    ")\n",
    "\n",
    "answer_settings = AnswerSettings(\n",
    "    evidence_k = 30, # number of evidence text chunks to retrieve (default=10)\n",
    "    evidence_summary_length = \"about 200 words\", # length of evidence summary (default=\"about 100 words\")\n",
    "    answer_max_sources = 15, # max number of sources to use for answering (default=5)\n",
    "    answer_length = \"about 400 words, but can be longer\", # length of final answer (default=\"about 200 words, but can be longer\")\n",
    ")\n",
    "\n",
    "parse_settings = ParsingSettings(\n",
    "    chunk_size=5_000,\n",
    "    use_doc_details=True,\n",
    "    overlap=250\n",
    ")\n",
    "\n",
    "prompt_settings = PromptSettings()\n",
    "\n",
    "settings = Settings(\n",
    "    agent = agent_settings, \n",
    "    answer = answer_settings,\n",
    "    parsing = parse_settings,\n",
    "    prompts = prompt_settings,\n",
    "    llm=default_lmm, \n",
    "    summary_llm=default_lmm,\n",
    "    embedding=\"text-embedding-3-small\", # default\n",
    "    temperature = 0.0, # default\n",
    "    texts_index_mmr_lambda = 1.0, # Lambda MMR (default)\n",
    "    index_absolute_directory = index_settings.use_absolute_paper_directory,\n",
    "    index_directory = index_settings.index_directory,\n",
    "    index_recursively = index_settings.recurse_subdirectories,\n",
    "    manifest_file = index_settings.manifest_file,\n",
    "    paper_directory = index_settings.paper_directory,\n",
    "    verbosity = 0, # (0-3), where 3 is all LLM/Embedding calls are logged\n",
    ")\n",
    "\n",
    "# Make sure that I am using the defautl arguments where it matters\n",
    "def print_non_default_settings(settings_defined, settings_classs, settings_name):\n",
    "    print(f\"------\\n{settings_name}\")\n",
    "    for key, value in settings_defined.__dict__.items():\n",
    "        default_value = getattr(settings_classs(), key, None)\n",
    "        if value != default_value:\n",
    "            print(f\"selected: {key}: {value}\")\n",
    "            print(f\"-> default: {key}: {default_value}\")\n",
    "\n",
    "# Print non-default settings for each object\n",
    "#print_non_default_settings(index_settings, IndexSettings, \"index_settings\")\n",
    "#print_non_default_settings(agent_settings, AgentSettings, \"agent_settings\")\n",
    "#print_non_default_settings(answer_settings, AnswerSettings, \"answer_settings\")\n",
    "#print_non_default_settings(parse_settings, ParsingSettings, \"parse_settings\")\n",
    "#print_non_default_settings(prompt_settings, PromptSettings, \"prompt_settings\")\n",
    "#print_non_default_settings(settings, Settings, \"settings\")\n",
    "\n",
    "# check API_KEYS are present\n",
    "API_KEYS = [\"DEEPSEEK_API_KEY\", \"OPENAI_API_KEY\"]\n",
    "for api_key in API_KEYS:\n",
    "    if (key := os.getenv(api_key)):\n",
    "        print(f\"{api_key} found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Name: pqa_index_MS_EXPORT\n",
      "Number of Indexed Files: 232\n"
     ]
    }
   ],
   "source": [
    "search_index = await build_search_index(settings=settings, bibtex_file=bibtex_file, manifest_file=manifest_file)\n",
    "assert search_index.index_name == settings.agent.index.name\n",
    "print(f\"Index Name: {search_index.index_name}\")\n",
    "print(f\"Number of Indexed Files: {len((await search_index.index_files).keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m07:56:22 - LiteLLM Router:INFO\u001b[0m: router.py:609 - Routing strategy: simple-shuffle\n",
      "\u001b[92m07:56:22 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:56:26 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:56:26 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:56:28 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:56:29 - LiteLLM Router:INFO\u001b[0m: router.py:609 - Routing strategy: simple-shuffle\n",
      "\u001b[92m07:56:29 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:56:29 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:56:29 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:56:29 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:56:35 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:56:35 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:56:35 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:56:35 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:56:35 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:56:35 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:56:37 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:56:37 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:56:40 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:56:40 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:56:41 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:56:41 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:56:42 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:56:42 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:56:43 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:56:43 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:56:46 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:56:46 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:56:46 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:56:46 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:56:47 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:56:47 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:56:48 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:56:48 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:56:51 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:56:51 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:56:52 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:56:52 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:56:53 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:56:53 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:56:54 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:56:54 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:56:56 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:56:56 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:56:57 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:56:57 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:56:58 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:56:58 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:57:00 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:57:00 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:57:01 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:57:01 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:57:03 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:57:03 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:57:05 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:57:05 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:57:05 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:57:05 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:57:07 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:57:07 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:57:08 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:57:08 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:57:10 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:57:10 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:57:12 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:57:12 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:57:12 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:57:14 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:57:14 - LiteLLM Router:INFO\u001b[0m: router.py:609 - Routing strategy: simple-shuffle\n",
      "\u001b[92m07:57:14 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:57:29 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n",
      "\u001b[92m07:57:29 - LiteLLM:INFO\u001b[0m: utils.py:2788 - \n",
      "LiteLLM completion() model= deepseek-chat; provider = deepseek\n",
      "\u001b[92m07:57:31 - LiteLLM Router:INFO\u001b[0m: router.py:957 - litellm.acompletion(model=deepseek/deepseek-chat)\u001b[32m 200 OK\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is known about the role of the gene HMOX1 in multiple sclerosis\n",
      "or related disorders?\n",
      "\n",
      "\n",
      "The gene **HMOX1**, encoding heme oxygenase-1 (HMOX1), plays a significant role\n",
      "in iron metabolism and inflammation in **multiple sclerosis (MS)**. HMOX1 is\n",
      "the inducible and rate-limiting enzyme in heme catabolism, responsible for\n",
      "degrading heme into iron, biliverdin, and carbon monoxide. In MS, HMOX1 is\n",
      "strongly upregulated in **CD163 co-expressing myeloid cells (MCs)** at the\n",
      "edges of chronic active lesions, suggesting its involvement in hemoglobin\n",
      "scavenging, a major source of iron in these cells (Hofmann2023 pages 13-15).\n",
      "This upregulation is spatially restricted to lesion rims (LR) compared to\n",
      "normal-appearing white matter (NAWM) and control areas, indicating a localized\n",
      "role in iron metabolism at lesion sites (Hofmann2023 pages 6-7).\n",
      "\n",
      "\n",
      "HMOX1 is also expressed by glial cells and has been observed in both active and\n",
      "chronic active MS lesions. Its expression is associated with **CD163+ and IL10+\n",
      "cells**, linking it to iron metabolism and inflammatory responses (Hofmann2023\n",
      "pages 10-12). The concomitant upregulation of HMOX1 in MCs expressing CD163\n",
      "supports the interpretation that this receptor is actively involved in\n",
      "hemoglobin scavenging, contributing to iron accumulation at lesion sites\n",
      "(Hofmann2023 pages 13-15). Additionally, HMOX1's role in iron metabolism is\n",
      "linked to the regulation of iron export, as evidenced by the upregulation of\n",
      "**HAMP**, which encodes hepcidin, a key regulator of iron export, in MCs at MS\n",
      "lesion areas. This suggests that iron is actively retained within MCs,\n",
      "preventing its release into the surrounding tissue environment (Hofmann2023\n",
      "pages 13-15).\n",
      "\n",
      "\n",
      "The **CD163-HMOX1-HAMP axis** is upregulated in MC subtypes at chronic active\n",
      "lesion rims, highlighting the importance of haptoglobin-bound hemoglobin as a\n",
      "critical source for MC-associated iron uptake in MS (Hofmann2023 pages 1-2).\n",
      "This axis is particularly relevant in **paramagnetic rim lesions (PRLs)**,\n",
      "where higher levels of soluble CD163 (sCD163) in cerebrospinal fluid (CSF)\n",
      "correlate with increased PRL counts, emphasizing the role of iron metabolism in\n",
      "MS progression (Hofmann2023 pages 1-2).\n",
      "\n",
      "\n",
      "HMOX1 is also implicated in oxidative stress responses, which are key features\n",
      "of MS pathology. It is differentially upregulated in glial cells in response to\n",
      "oxidative stress and demyelinating conditions, suggesting a potential\n",
      "protective or regulatory role in MS (Hofmann2023 pages 17-17). Overall, HMOX1\n",
      "appears to be a critical player in the iron metabolism and inflammatory\n",
      "processes associated with MS lesion formation and progression (Hofmann2023\n",
      "pages 13-15, Hofmann2023 pages 6-7).\n",
      "\n",
      "\n",
      "References\n",
      "\n",
      "\n",
      "1. (Hofmann2023 pages 13-15): Hofmann, Annika, et al. \"Myeloid Cell Iron Uptake\n",
      "Pathways and Paramagnetic Rim Formation in Multiple Sclerosis.\" *Acta\n",
      "Neuropathologica*, vol. 146, 2023, pp. 707–724. Springer,\n",
      "https://doi.org/10.1007/s00401-023-02627-4. Accessed 2024.\n",
      "\n",
      "\n",
      "2. (Hofmann2023 pages 1-2): Hofmann, Annika, et al. \"Myeloid Cell Iron Uptake\n",
      "Pathways and Paramagnetic Rim Formation in Multiple Sclerosis.\" *Acta\n",
      "Neuropathologica*, vol. 146, 2023, pp. 707–724. Springer,\n",
      "https://doi.org/10.1007/s00401-023-02627-4. Accessed 2024.\n",
      "\n",
      "\n",
      "3. (Hofmann2023 pages 10-12): Hofmann, Annika, et al. \"Myeloid Cell Iron Uptake\n",
      "Pathways and Paramagnetic Rim Formation in Multiple Sclerosis.\" *Acta\n",
      "Neuropathologica*, vol. 146, 2023, pp. 707–724. Springer,\n",
      "https://doi.org/10.1007/s00401-023-02627-4. Accessed 2024.\n",
      "\n",
      "\n",
      "4. (Hofmann2023 pages 6-7): Hofmann, Annika, et al. \"Myeloid Cell Iron Uptake\n",
      "Pathways and Paramagnetic Rim Formation in Multiple Sclerosis.\" *Acta\n",
      "Neuropathologica*, vol. 146, 2023, pp. 707–724. Springer,\n",
      "https://doi.org/10.1007/s00401-023-02627-4. Accessed 2024.\n",
      "\n",
      "\n",
      "5. (Hofmann2023 pages 17-17): Hofmann, Annika, et al. \"Myeloid Cell Iron Uptake\n",
      "Pathways and Paramagnetic Rim Formation in Multiple Sclerosis.\" *Acta\n",
      "Neuropathologica*, vol. 146, 2023, pp. 707–724. Springer,\n",
      "https://doi.org/10.1007/s00401-023-02627-4. Accessed 2024.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer_response = await agent_query(\n",
    "    query=\"What is known about the role of the gene HMOX1 in multiple sclerosis or related disorders?\", \n",
    "    settings=settings, rebuild_index=False\n",
    ")\n",
    "pretty_print_text(answer_response.session.formatted_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Previous Question & Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Indexed Answers: 3\n",
      "Number of Answers Matching Query: 3\n"
     ]
    }
   ],
   "source": [
    "query_answer_index_results = await query_answer_index(settings=settings, query=\"role of perivascular niche in MS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paperqa.utils import parse_string, clean_upbibtex, unsrtalpha, CitationConversionError, Person, Parser, FieldIsMissing\n",
    "\n",
    "\n",
    "def format_bibtex(\n",
    "    bibtex: str,\n",
    "    key: str | None = None,\n",
    "    clean: bool = True,\n",
    "    missing_replacements: dict[str, str] | None = None,\n",
    ") -> str:\n",
    "    \"\"\"Transform bibtex entry into a citation, potentially adding missing fields.\"\"\"\n",
    "    style = unsrtalpha.Style()\n",
    "    if missing_replacements is None:\n",
    "        missing_replacements = {}\n",
    "    try:\n",
    "        bd = parse_string(clean_upbibtex(bibtex) if clean else bibtex, \"bibtex\")\n",
    "        key = list(bd.entries.keys())[0]\n",
    "    except Exception:\n",
    "        key = bibtex.split(\",\")[0]\n",
    "        key = key.replace(\"{{\", \"{\")\n",
    "        key = key.split(\"{\")[1]\n",
    "        return \"Ref \" + key\n",
    "    try:\n",
    "        entry = bd.entries[key]\n",
    "    except KeyError as exc:  # Let's check if key is a non-empty prefix\n",
    "        try:\n",
    "            entry = next(\n",
    "                iter(v for k, v in bd.entries.items() if k.startswith(key) and key)\n",
    "            )\n",
    "        except StopIteration:\n",
    "            raise CitationConversionError(\n",
    "                f\"Failed to process{' and clean up' if clean else ''} bibtex {bibtex}\"\n",
    "                f\" due to failed lookup of key {key}.\"\n",
    "            ) from exc\n",
    "    try:\n",
    "        # see if we can insert missing fields\n",
    "        for field, replacement_value in missing_replacements.items():\n",
    "            # Deal with special case for author, since it needs to be parsed\n",
    "            # into Person objects. This reorganizes the names automatically.\n",
    "            if field == \"author\" and \"author\" not in entry.persons:\n",
    "                tmp_author_bibtex = f\"@misc{{tmpkey, author={{{replacement_value}}}}}\"\n",
    "                authors: list[Person] = (\n",
    "                    Parser()\n",
    "                    .parse_string(tmp_author_bibtex)\n",
    "                    .entries[\"tmpkey\"]\n",
    "                    .persons[\"author\"]\n",
    "                )\n",
    "                for a in authors:\n",
    "                    entry.add_person(a, \"author\")\n",
    "            elif field not in entry.fields:\n",
    "                entry.fields.update({field: replacement_value})\n",
    "        entry = style.format_entry(label=\"1\", entry=entry)\n",
    "        return entry.text.render_as(\"text\")\n",
    "    except (FieldIsMissing, UnicodeDecodeError):\n",
    "        try:\n",
    "            return entry.fields[\"title\"]\n",
    "        except KeyError as exc:\n",
    "            raise CitationConversionError(\n",
    "                f\"Failed to process{' and clean up' if clean else ''} bibtex {bibtex}\"\n",
    "                \" due to missing a 'title' field.\"\n",
    "            ) from exc\n",
    "    \n",
    "missing_replacements = None\n",
    "clean = True\n",
    "bibtex = \"\"\"@article{{tortosacarreres}2024predictivepotentialof,\n",
    "    author = \"{Tortosa-Carreres}, Jordi and {Cubas-N{\\'u}{\\\\textasciitilde n}ez}, Laura and {Quiroga-Varela}, Ana and {Castillo-Villalba}, Jessica and {Rami{\\'o}-Torrenta}, Llu{\\'i}s and Piqueras, M{\\'o}nica and {Gasqu{\\'e}-Rubio}, Raquel and {Quintanilla-Bordas}, Carlos and Sanz, Maria Teresa and Lucas, Celia and {Huertas-Pons}, Joana Mar{\\'i}a and Miguela, Albert and Casanova, Bonaventura and {Laiz-Marro}, Bego{\\\\textasciitilde n}a and {P{\\'e}rez-Miralles}, Francisco Carlos\",\n",
    "    title = \"Predictive Potential of Serum and Cerebrospinal Fluid Biomarkers for Disease Activity in Treated Multiple Sclerosis Patients\",\n",
    "    year = \"2024\",\n",
    "    journal = \"Multiple Sclerosis and Related Disorders\",\n",
    "    doi = \"10.1016/j.msard.2024.105734\",\n",
    "    url = \"https://doi.org/10.1016/j.msard.2024.105734\",\n",
    "    publisher = \"Elsevier\",\n",
    "    issn = \"2211-0348, 2211-0356\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"Transform bibtex entry into a citation, potentially adding missing fields.\"\"\"\n",
    "style = unsrtalpha.Style()\n",
    "if missing_replacements is None:\n",
    "    missing_replacements = {}\n",
    "try:\n",
    "    print(bibtex)\n",
    "    bd = parse_string(clean_upbibtex(bibtex) if clean else bibtex, \"bibtex\")\n",
    "    key = list(bd.entries.keys())[0]\n",
    "except Exception:\n",
    "    key = bibtex.split(\",\")[0]\n",
    "    key = key.replace(\"{{\", \"{\")\n",
    "    key = key.split(\"{\")[1]\n",
    "    print(\"Ref \" + key)\n",
    "try:\n",
    "    entry = bd.entries[key]\n",
    "    print(entry)\n",
    "except KeyError as exc:  # Let's check if key is a non-empty prefix\n",
    "    try:\n",
    "        entry = next(\n",
    "            iter(v for k, v in bd.entries.items() if k.startswith(key) and key)\n",
    "        )\n",
    "    except StopIteration:\n",
    "        raise CitationConversionError(\n",
    "            f\"Failed to process{' and clean up' if clean else ''} bibtex {bibtex}\"\n",
    "            f\" due to failed lookup of key {key}.\"\n",
    "        ) from exc\n",
    "try:\n",
    "    # see if we can insert missing fields\n",
    "    for field, replacement_value in missing_replacements.items():\n",
    "        # Deal with special case for author, since it needs to be parsed\n",
    "        # into Person objects. This reorganizes the names automatically.\n",
    "        if field == \"author\" and \"author\" not in entry.persons:\n",
    "            tmp_author_bibtex = f\"@misc{{tmpkey, author={{{replacement_value}}}}}\"\n",
    "            authors: list[Person] = (\n",
    "                Parser()\n",
    "                .parse_string(tmp_author_bibtex)\n",
    "                .entries[\"tmpkey\"]\n",
    "                .persons[\"author\"]\n",
    "            )\n",
    "            for a in authors:\n",
    "                entry.add_person(a, \"author\")\n",
    "        elif field not in entry.fields:\n",
    "            entry.fields.update({field: replacement_value})\n",
    "    entry = style.format_entry(label=\"1\", entry=entry)\n",
    "    print(entry.text.render_as(\"text\"))\n",
    "except (FieldIsMissing, UnicodeDecodeError):\n",
    "    try:\n",
    "        print(entry.fields[\"title\"])\n",
    "    except KeyError as exc:\n",
    "        raise CitationConversionError(\n",
    "            f\"Failed to process{' and clean up' if clean else ''} bibtex {bibtex}\"\n",
    "            \" due to missing a 'title' field.\"\n",
    "        ) from exc\n",
    "\n",
    "\n",
    "#test = \"\"\"@article{{tortosacarreres}2024predictivepotentialof,\n",
    "#    author = \"{Tortosa-Carreres}, Jordi and {Cubas-N{\\'u}{\\\\textasciitilde n}ez}, Laura and {Quiroga-Varela}, Ana and {Castillo-Villalba}, Jessica and {Rami{\\'o}-Torrenta}, Llu{\\'i}s and Piqueras, M{\\'o}nica and {Gasqu{\\'e}-Rubio}, Raquel and {Quintanilla-Bordas}, Carlos and Sanz, Maria Teresa and Lucas, Celia and {Huertas-Pons}, Joana Mar{\\'i}a and Miguela, Albert and Casanova, Bonaventura and {Laiz-Marro}, Bego{\\\\textasciitilde n}a and {P{\\'e}rez-Miralles}, Francisco Carlos\",\n",
    "#    title = \"Predictive Potential of Serum and Cerebrospinal Fluid Biomarkers for Disease Activity in Treated Multiple Sclerosis Patients\",\n",
    "#    year = \"2024\",\n",
    "#    journal = \"Multiple Sclerosis and Related Disorders\",\n",
    "#    doi = \"10.1016/j.msard.2024.105734\",\n",
    "#    url = \"https://doi.org/10.1016/j.msard.2024.105734\",\n",
    "#    publisher = \"Elsevier\",\n",
    "#    issn = \"2211-0348, 2211-0356\"\n",
    "#\"\"\"\n",
    "#format_bibtex(test)\n",
    "#parse_string(clean_upbibtex(test), \"bibtex\")\n",
    "\n",
    "bd = parse_string(clean_upbibtex(bibtex) if clean else bibtex, \"bibtex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bibtex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"\"\"@article{tortosacarreres2024predictivepotentialof,\n",
    "  author = \"Tortosa-Carreres, Jordi and Cubas-Núñez, Laura and Quiroga-Varela, Ana and Castillo-Villalba, Jessica and Ramió-Torrenta, Lluís and Piqueras, Mónica and Gasqué-Rubio, Raquel and Quintanilla-Bordas, Carlos and Sanz, Maria Teresa and Lucas, Celia and Huertas-Pons, Joana María and Miguela, Albert and Casanova, Bonaventura and Laiz-Marro, Begoña and Pérez-Miralles, Francisco Carlos\",\n",
    "  title = \"Predictive Potential of Serum and Cerebrospinal Fluid Biomarkers for Disease Activity in Treated Multiple Sclerosis Patients\",\n",
    "  year = \"2024\",\n",
    "  journal = \"Multiple Sclerosis and Related Disorders\",\n",
    "  doi = \"10.1016/j.msard.2024.105734\",\n",
    "  url = \"https://doi.org/10.1016/j.msard.2024.105734\",\n",
    "  publisher = \"Elsevier\",\n",
    "  issn = \"2211-0348, 2211-0356\"\n",
    "}\"\"\"\n",
    "parse_string(test, bib_format=\"bibtex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"\"\"@article{tortosacarreres2024predictivepotentialof,\n",
    "    author = \"foo, bar\",\n",
    "    title = \"Predictive Potential of Serum and Cerebrospinal Fluid Biomarkers for Disease Activity in Treated Multiple Sclerosis Patients\",\n",
    "    year = \"2024\",\n",
    "    journal = \"Multiple Sclerosis and Related Disorders\",\n",
    "    doi = \"10.1016/j.msard.2024.105734\",\n",
    "    url = \"https://doi.org/10.1016/j.msard.2024.105734\",\n",
    "    publisher = \"Elsevier\",\n",
    "    issn = \"2211-0348\"\n",
    "}\"\"\"\n",
    "parse_string(test, bib_format=\"bibtex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DocDetails(**doc_details_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybtex\n",
    "\n",
    "bib_file = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = False\n",
    "bd = parse_string(clean_upbibtex(test) if clean else test, \"bibtex\")\n",
    "list(bd.entries.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = parse_string(clean_upbibtex(bibtex) if clean else bibtex, \"bibtex\")\n",
    "bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paperqa-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
